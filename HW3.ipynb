{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Домашнее задание"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. обучить несколько разных моделей на наборе данных ССЗ (train_case2.csv): логрег, бустинг, лес и т.д - на ваш выбор 2-3 варианта\n",
    "2. при обучении моделей обязательно использовать кроссвалидацию\n",
    "3. вывести сравнение полученных моделей по основным метрикам классификации: pr/rec/auc/f_score (можно в виде таблицы, где строки - модели, а столбцы - метрики)\n",
    "4. сделать выводы о том, какая модель справилась с задачей лучше других\n",
    "5. (опциональный вопрос) какая метрика (precision_recall_curve или roc_auc_curve) больше подходит в случае сильного дисбаланса классов? (когда объектов одного из классов намного больше чем другого).\n",
    "\n",
    "p.s.В вопросе проще разобраться, если вспомнить оси на графике roc auc curve и рассмотреть такой пример:\n",
    "\n",
    "Имеется 100000 объектов, из которых только 100 - класс \"1\" (99900 - класс \"0\", соответственно).\n",
    "Допустим, у нас две модели:\n",
    "\n",
    "- первая помечает 100 объектов как класс 1, но TP = 90\n",
    "- вторая помечает 1000 объектов как класс 1, но TP такой же - 90\n",
    "\n",
    "Какая модель лучше и почему? И что позволяет легче сделать вывод - roc_auc_curve или precision_recall_curve?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier as xgbc\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n0   0  18393       2     168    62.0    110     80            1     1      0   \n1   1  20228       1     156    85.0    140     90            3     1      0   \n2   2  18857       1     165    64.0    130     70            3     1      0   \n\n   alco  active  cardio  \n0     0       1       0  \n1     0       1       1  \n2     0       0       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>height</th>\n      <th>weight</th>\n      <th>ap_hi</th>\n      <th>ap_lo</th>\n      <th>cholesterol</th>\n      <th>gluc</th>\n      <th>smoke</th>\n      <th>alco</th>\n      <th>active</th>\n      <th>cardio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>18393</td>\n      <td>2</td>\n      <td>168</td>\n      <td>62.0</td>\n      <td>110</td>\n      <td>80</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>20228</td>\n      <td>1</td>\n      <td>156</td>\n      <td>85.0</td>\n      <td>140</td>\n      <td>90</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>18857</td>\n      <td>1</td>\n      <td>165</td>\n      <td>64.0</td>\n      <td>130</td>\n      <td>70</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_case2.csv', ';')\n",
    "df.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Разделим наши данные на тренировочную и тестовую выборки"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "#разделим данные на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('cardio', 1),\n",
    "                                                    df['cardio'], random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "К полям:\n",
    "- gender, cholesterol применим OHE-кодирование\n",
    "- age, height, weight, ap_hi, ap_lo - standardScaler\n",
    "- gluc, smoke, alco, active - оставим пока как есть"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "\n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "\n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in test_columns:\n",
    "            if col_ not in self.columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "continuos_cols = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "cat_cols = ['gender', 'cholesterol']\n",
    "base_cols = ['gluc', 'smoke', 'alco', 'active']\n",
    "\n",
    "continuos_transformers = []\n",
    "cat_transformers = []\n",
    "base_transformers = []\n",
    "\n",
    "for cont_col in continuos_cols:\n",
    "    transfomer =  Pipeline([\n",
    "                ('selector', NumberSelector(key=cont_col)),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "    continuos_transformers.append((cont_col, transfomer))\n",
    "\n",
    "for cat_col in cat_cols:\n",
    "    cat_transformer = Pipeline([\n",
    "                ('selector', ColumnSelector(key=cat_col)),\n",
    "                ('ohe', OHEEncoder(key=cat_col))\n",
    "            ])\n",
    "    cat_transformers.append((cat_col, cat_transformer))\n",
    "\n",
    "for base_col in base_cols:\n",
    "    base_transformer = Pipeline([\n",
    "                ('selector', NumberSelector(key=base_col))\n",
    "            ])\n",
    "    base_transformers.append((base_col, base_transformer))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь объединим все наши трансформеры с помощью FeatureUnion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-1.73391771,  0.6873301 ,  0.74843904, ...,  1.        ,\n         0.        ,  1.        ],\n       [-1.67343538,  0.07758923, -0.29640123, ...,  0.        ,\n         0.        ,  1.        ],\n       [ 0.13738132,  1.17512278, -0.15708919, ...,  0.        ,\n         0.        ,  0.        ],\n       ...,\n       [ 1.17775864,  1.17512278, -0.15708919, ...,  0.        ,\n         0.        ,  1.        ],\n       [-0.47190715, -1.38578883,  0.74843904, ...,  0.        ,\n         0.        ,  1.        ],\n       [ 0.38174619,  0.56538192, -0.08743318, ...,  0.        ,\n         0.        ,  1.        ]])"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "feats = FeatureUnion(continuos_transformers+cat_transformers+base_transformers)\n",
    "feature_processing = Pipeline([('feats', feats)])\n",
    "\n",
    "feature_processing.fit_transform(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "def model(model):\n",
    "    classifier = Pipeline([\n",
    "        ('features',feats),\n",
    "        ('classifier', model),\n",
    "    ])\n",
    "\n",
    "\n",
    "    #запустим кросс-валидацию\n",
    "    cv_scores = cross_val_score(classifier, X_train, y_train, cv=7, scoring='roc_auc')\n",
    "    cv_score = np.mean(cv_scores)\n",
    "    cv_score_std = np.std(cv_scores)\n",
    "    print('CV score is {}+-{}'.format(cv_score, cv_score_std))\n",
    "\n",
    "    #обучим пайплайн на всем тренировочном датасете\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_score = classifier.predict_proba(X_test)[:, 1]\n",
    "    return y_score, classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "def metrics(y_score, classifier):\n",
    "    b=1\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test.values, y_score)\n",
    "    fscore = (1+b**2)*(precision * recall) / (b**2*precision + recall)\n",
    "    # locate the index of the largest f score\n",
    "    ix = np.argmax(fscore)\n",
    "    print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix],\n",
    "                                                                            fscore[ix],\n",
    "                                                                            precision[ix],\n",
    "                                                                            recall[ix]))\n",
    "    roc_auc = roc_auc_score(y_true=y_test, y_score=classifier.predict_proba(X_test)[:,1])\n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_test, y_score>thresholds[ix])\n",
    "    TN = cnf_matrix[0][0]\n",
    "    FN = cnf_matrix[1][0]\n",
    "    TP = cnf_matrix[1][1]\n",
    "    FP = cnf_matrix[0][1]\n",
    "\n",
    "    TPR = TP/(TP+FN)\n",
    "    FPR = FP/(FP+TN)\n",
    "    TNR = TN/(FP+TN)\n",
    "\n",
    "\n",
    "\n",
    "    m_values = [precision[ix],\n",
    "                recall[ix],\n",
    "                fscore[ix],\n",
    "                roc_auc,\n",
    "                TPR,\n",
    "                FPR,\n",
    "                TNR]\n",
    "\n",
    "    return m_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "# Создадим таблицу для сравнения метрик\n",
    "results = pd.DataFrame(columns=['Model','Precision', 'Recall', \"Roc Auc\", 'F-Score', 'TPR', 'FPR', 'TNR'])\n",
    "results['Model'] = ['LogReg','XGBoost', 'Random Forest Classifier']\n",
    "results.set_index('Model', drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 0.7864573689384385+-0.004422021036885763\n"
     ]
    }
   ],
   "source": [
    "# Первая модель логистическая регрессия\n",
    "y_score, classifier = model(LogisticRegression(random_state = 42))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.386937, F-Score=0.730, Precision=0.647, Recall=0.838\n"
     ]
    }
   ],
   "source": [
    "# Считаем метрики\n",
    "metrics_values = metrics(y_score, classifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "# Добавляем в таблицу\n",
    "results.loc['LogReg'] = metrics_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 0.7971556462159913+-0.0025807632015828223\n"
     ]
    }
   ],
   "source": [
    "# Вторая модель XGBoost\n",
    "y_score, classifier = model(xgbc(random_state = 42, verbosity = 0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.347103, F-Score=0.738, Precision=0.665, Recall=0.828\n"
     ]
    }
   ],
   "source": [
    "# Считаем метрики\n",
    "metrics_values = metrics(y_score, classifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "# Добавляем в таблицу\n",
    "results.loc['XGBoost'] = metrics_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score is 0.7743796633622809+-0.003611330100912611\n"
     ]
    }
   ],
   "source": [
    "# Третья модель Random Forest Classifier\n",
    "y_score, classifier = model(rfc(random_state = 42))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.350000, F-Score=0.719, Precision=0.643, Recall=0.816\n"
     ]
    }
   ],
   "source": [
    "# Считаем метрики\n",
    "metrics_values = metrics(y_score, classifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "# Добавляем в таблицу\n",
    "results.loc['Random Forest Classifier'] = metrics_values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "                         Precision    Recall   Roc Auc   F-Score       TPR  \\\nModel                                                                        \nLogReg                    0.647431  0.837558  0.730323  0.784035  0.837442   \nXGBoost                   0.665248  0.828341   0.73789  0.797228  0.828226   \nRandom Forest Classifier  0.642669  0.815553  0.718863  0.771037   0.80841   \n\n                               FPR       TNR  \nModel                                         \nLogReg                    0.448866  0.551134  \nXGBoost                   0.410204  0.589796  \nRandom Forest Classifier  0.434127  0.565873  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n      <th>F-Score</th>\n      <th>TPR</th>\n      <th>FPR</th>\n      <th>TNR</th>\n    </tr>\n    <tr>\n      <th>Model</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LogReg</th>\n      <td>0.647431</td>\n      <td>0.837558</td>\n      <td>0.730323</td>\n      <td>0.784035</td>\n      <td>0.837442</td>\n      <td>0.448866</td>\n      <td>0.551134</td>\n    </tr>\n    <tr>\n      <th>XGBoost</th>\n      <td>0.665248</td>\n      <td>0.828341</td>\n      <td>0.73789</td>\n      <td>0.797228</td>\n      <td>0.828226</td>\n      <td>0.410204</td>\n      <td>0.589796</td>\n    </tr>\n    <tr>\n      <th>Random Forest Classifier</th>\n      <td>0.642669</td>\n      <td>0.815553</td>\n      <td>0.718863</td>\n      <td>0.771037</td>\n      <td>0.80841</td>\n      <td>0.434127</td>\n      <td>0.565873</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Все модели показали примерно одинаковые результаты, хотя по многим метрикам XGBoost немного лучше. Для данного типа задач имеет смысл максимизировать precision, так как он помогает максимально предсказывать Positive объекты, что важно в вопросах медицинской диагностики.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}